{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d26be96b-7e92-45e9-99e9-46efba123f10",
   "metadata": {},
   "source": [
    "# Importing all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "630cf350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9327932-4989-4091-b713-18b5c4504798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already extracted.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The dataset directory structure is incorrect. Each class should have its own subdirectory.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m root, dirs, files \u001b[38;5;129;01min\u001b[39;00m os.walk(extract_path):\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dirs:\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mThe dataset directory structure is incorrect. Each class should have its own subdirectory.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Define image size and batch size\u001b[39;00m\n\u001b[32m     21\u001b[39m IMG_SIZE = (\u001b[32m150\u001b[39m, \u001b[32m150\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: The dataset directory structure is incorrect. Each class should have its own subdirectory."
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract the dataset\n",
    "zip_path = 'Dataset.zip'\n",
    "extract_path = '/home/manishji/Smart_Mathematics_Tutor/Dataset'\n",
    "if not os.path.exists(extract_path):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_path)\n",
    "    print(\"Dataset extracted successfully!\")\n",
    "else:\n",
    "    print(\"Dataset already extracted.\")\n",
    "\n",
    "# Check if the dataset directory is not empty\n",
    "if not os.listdir(extract_path):\n",
    "    raise ValueError(\"The dataset directory is empty. Please check the extraction path and dataset.\")\n",
    "\n",
    "# Ensure the directory structure is correct\n",
    "for root, dirs, files in os.walk(extract_path):\n",
    "    if not dirs:\n",
    "        raise ValueError(\"The dataset directory structure is incorrect. Each class should have its own subdirectory.\")\n",
    "\n",
    "# Define image size and batch size\n",
    "IMG_SIZE = (150, 150)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Create ImageDataGenerator instances for training and validation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Load the training dataset (80% for training)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    extract_path,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "# Load the validation dataset (20% for validation)\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    extract_path,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"validation\"\n",
    ")\n",
    "\n",
    "# Print dataset sizes and class labels\n",
    "print(f\"Training Samples: {train_generator.samples}\")\n",
    "print(f\"Validation Samples: {val_generator.samples}\")\n",
    "print(f\"Class labels: {train_generator.class_indices}\")\n",
    "\n",
    "# Check if any of the datasets are empty\n",
    "if train_generator.samples == 0:\n",
    "    raise ValueError(\"The training dataset is empty. Please check the dataset directory and ensure it contains images.\")\n",
    "if val_generator.samples == 0:\n",
    "    raise ValueError(\"The validation dataset is empty. Please check the dataset directory and ensure it contains images.\")\n",
    "\n",
    "# Define the model\n",
    "def build_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(150, 150, 3)),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(len(train_generator.class_indices), activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Build and summarize the model\n",
    "model = build_model()\n",
    "model.summary()\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // BATCH_SIZE,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "loss, accuracy = model.evaluate(val_generator, steps=val_generator.samples // BATCH_SIZE)\n",
    "print(f'Validation accuracy: {accuracy}')\n",
    "\n",
    "# Plot training & validation accuracy/loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Save the trained model\n",
    "model.save('trained_model_with_early_stopping.h5')\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(\"trained_model_with_early_stopping.h5\")\n",
    "\n",
    "# Predict on new images\n",
    "def predict_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(150, 150))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = x / 255.0\n",
    "    pred = np.argmax(model.predict(x))\n",
    "    return pred\n",
    "\n",
    "# Example usage\n",
    "index = ['circle', 'square', 'triangle']\n",
    "img_path = \"/home/manishji/Downloads/100.png\"\n",
    "prediction = index[predict_image(img_path)]\n",
    "print(f'Prediction: {prediction}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461eb4c2-d490-4d43-b80b-0257d69c699a",
   "metadata": {},
   "source": [
    "# Image Data Augumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dba8068a-e12e-412f-a6a9-16b7966509d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already extracted.\n"
     ]
    }
   ],
   "source": [
    " #Extract the dataset\n",
    "zip_path = 'Dataset.zip'\n",
    "extract_path = '/home/manishji/Smart_Mathematics_Tutor/Dataset'\n",
    "if not os.path.exists(extract_path):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_path)\n",
    "    print(\"Dataset extracted successfully!\")\n",
    "else:\n",
    "    print(\"Dataset already extracted.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fddc59-fb78-49d1-be2d-f07dede667b0",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c851cdf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8994 images belonging to 1 classes.\n",
      "Found 2248 images belonging to 1 classes.\n",
      "Training Samples: 8994\n",
      "Validation Samples: 2248\n",
      "Class labels: {'Dataset': 0}\n"
     ]
    }
   ],
   "source": [
    "# Define image size and batch size\n",
    "IMG_SIZE = (150, 150)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Create ImageDataGenerator instances for training and validation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Load the training dataset (80% for training)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    extract_path,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "# Load the validation dataset\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    extract_path,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"validation\"\n",
    ")\n",
    "\n",
    "# Print dataset sizes and class labels\n",
    "print(f\"Training Samples: {train_generator.samples}\")\n",
    "print(f\"Validation Samples: {val_generator.samples}\")\n",
    "print(f\"Class labels: {train_generator.class_indices}\")\n",
    "\n",
    "# Check if any of the datasets are empty\n",
    "if train_generator.samples == 0:\n",
    "    raise ValueError(\"The training dataset is empty. Please check the dataset directory and ensure it contains images.\")\n",
    "if val_generator.samples == 0:\n",
    "    raise ValueError(\"The validation dataset is empty. Please check the dataset directory and ensure it contains images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a563527b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8994 images belonging to 1 classes.\n",
      "Found 2248 images belonging to 1 classes.\n",
      "Training Samples: 8994\n",
      "Validation Samples: 2248\n"
     ]
    }
   ],
   "source": [
    "# Define image size and batch size\n",
    "IMG_SIZE = (150, 150)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Create ImageDataGenerator instances for training and validation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Load the training dataset (80% for training)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    extract_path,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "# Load the validation dataset (20% for validation)\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    extract_path,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"validation\"\n",
    ")    \n",
    "# Print dataset sizes\n",
    "print(f\"Training Samples: {train_generator.samples}\")\n",
    "print(f\"Validation Samples: {val_generator.samples}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1863c1be-5115-45a7-b159-e6b832bab711",
   "metadata": {},
   "source": [
    "# Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa77d32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "def build_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(150, 150, 3)),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.5),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(len(train_generator.class_indices), activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78ffb1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manishji/Smart_Mathematics_Tutor/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-03-19 17:46:20.248506: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2025-03-19 17:46:20.406295: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 42467328 exceeds 10% of free system memory.\n",
      "2025-03-19 17:46:20.421390: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 42467328 exceeds 10% of free system memory.\n",
      "2025-03-19 17:46:20.431987: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 42467328 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41472</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">10,617,088</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m9,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41472\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │    \u001b[38;5;34m10,617,088\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,940,449</span> (41.73 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,940,449\u001b[0m (41.73 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,938,785</span> (41.73 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,938,785\u001b[0m (41.73 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,664</span> (6.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,664\u001b[0m (6.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build and summarize the model\n",
    "model = build_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981b8dfc-9fac-48f7-a413-a5521fcaa429",
   "metadata": {},
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c5b7a06-5b89-4c57-be52-0964795aa5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manishji/Smart_Mathematics_Tutor/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manishji/Smart_Mathematics_Tutor/.venv/lib/python3.12/site-packages/keras/src/ops/nn.py:827: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n",
      "/home/manishji/Smart_Mathematics_Tutor/.venv/lib/python3.12/site-packages/keras/src/losses/losses.py:33: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n",
      "2025-03-19 17:46:29.498623: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 42467328 exceeds 10% of free system memory.\n",
      "2025-03-19 17:46:32.599748: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 92160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manishji/Smart_Mathematics_Tutor/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m923s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 2/20\n",
      "\u001b[1m  1/281\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13:43\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manishji/Smart_Mathematics_Tutor/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 3/20\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1339s\u001b[0m 5s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/20\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 5/20\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m767s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 6/20\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Define callbacks\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_loss')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // BATCH_SIZE,\n",
    "    epochs=20,  # Reduced number of epochs\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a808135-2cd3-485f-af24-8cb3328dee5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 457ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Validation accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    " #Evaluate the model on the validation set\n",
    "loss, accuracy = model.evaluate(val_generator, steps=val_generator.samples // BATCH_SIZE)\n",
    "print(f'Validation accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77dc8c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy/loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8486f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save('trained_model_with_early_stopping.keras')\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(\"trained_model_with_early_stopping.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a103889",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predict on new images\n",
    "def predict_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(150, 150))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = x / 255.0\n",
    "    pred = np.argmax(model.predict(x))\n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbc62e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step\n",
      "Prediction: circle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manishji/Smart_Mathematics_Tutor/.venv/lib/python3.12/site-packages/keras/src/ops/nn.py:827: UserWarning: You are using a softmax over axis -1 of a tensor of shape (1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "index = ['circle', 'square', 'triangle']\n",
    "img_path = \"/home/manishji/Downloads/s.png\"\n",
    "prediction = index[predict_image(img_path)]\n",
    "print(f'Prediction: {prediction}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55beeda4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
